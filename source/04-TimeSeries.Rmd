#Séries Temporais

Métodos de séries temporais são suficientemente extensos e únicos para terem seu próprio capítulo. Este capítulo trata dos principais métodos de séries temporais de interesse dos economistas: ARIMAs, VARs, testes de raiz unitária e cointegração. Séries temporais são únicas o suficiente a ponto de terem um classe própria - sem nenhuma surpresa, ela se chama _time series_.

##O básico

Suponha que você, usando os métodos do capítulo 2, inseriu uma série temporal no R. O R não sabe, _a priori_, que os dados são uma série temporal. Você precisa contar isso a ele, e o comando que faz isso é o `ts()`. O `ts` recebe a série, a data de ínicio e a frequência. A frequência é como você dividiu o ano: 4 se o dado for trimestral, 12 se for mensal...

Por exemplo, podemos gerar uma série de variáveis aleatórias da normal (um ruído branco) e transformar em série temporal mensal começando em janeiro de 2000:

```{r}

serie <- rnorm(1000)
serie <- ts(serie,start =c(2000,01), freq = 12)
```

Veja que o comando ts() é excessivamente engessado: os dados tem que ter uma frequência fixa, expressa como uma fração do ano. O pacote **zoo** extende bastante as capacidades do R em lidar com séries temporais, inclusive com séries irregulares. 

**Atenção: Séries Temporais e o lm**
Você *não* deve passar um objeto de série temporal para o `lm()`, já que o `lm` vai ignorar o formato de série temporal. Assim, estimar um modelo AR(1) usando `lm(y ~ lag(y))` vai gerar uma regressão com coeficiente 1 para lag(y) e $R^2 = 1$. De fato, a regressão feita foi y em y - o que não é uma regressão muito emocionante. 

##ARIMAs

Com uma série devidamente construída para ser um objeto ts - como nós fizemos acima- podemos tentar estimar algum modelo. O modelo base de séries temporais é o ARIMA. O R base já vem com muitas funções para lidar com isso, mas o pacote **forecast** extende bastante as capacidades do R em lidar com esse tipo de série. O primeiro passo para estimar um modelo Arima é obter a função de autocorrelação (FAC) e a função de autocorrelação parcial (FACP): elas são `Acf` e `Pacf`. Veja que existem versões na base do R que se chamam `acf` e `pacf` (notem que lá é com maiúscula e aqui com minúscula). A diferença _fundamental_ entre os dois é que a `Acf` e a `acf` (e também a `Pacf` e a `pacf`) é que a primeira exclui a autocorrelação no momento 0 - que é trivialmente 1. 

Uma vez conhecendo o formato da FAC e da FACP, podemos estimar o ARIMA. O comando para estimar um modelo ARIMA é `Arima` - e novamente, existe um `arima` com minúscula que é da base do R. O `Arima` basicamente recebe duas coisas, a série e a ordem do modelo(isso é, se o modelo é um ARMA(1,1), AR(1), MA(1) etc). Vamos gerar um exemplo de um AR(1) com dados simulados e obter a FAC e FACP e estimar o modelo Arma sugerido:

```{r}

library(forecast)

u <- rnorm(500)
y <- rep(0,500) #nossa futura série

y[1] <- u[1]

for(i in 2:500){
  y[i] <- 0.6*y[i-1] + u[i] #um AR(1) com coeficiente 0.6
}

Acf(y)
Pacf(y)

modelo <- Arima(serie,order=c(1,0,0))
summary(modelo)
```

Veja que o objeto `modelo` trás os coeficientes estimados, o erro padrão e alguns diagnósticos úteis como critérios de informação. 

Em algumas situações pode ser muito difícil inferir o modelo certo a partir da FAC e da FACP. O comando `auto.arima`, do pacote **forecast**, seleciona um modelo a partir de algum critério de informação. Vamos ilustrar o ponto gerando uma série `x` que é um ARMA(1,2):

```{r}

e <- rnorm(1000)

x <- rep(0,1000)

for(j in 1:998){
  x[j+2] <- 0.5*x[j+1] + e[j+2] - 0.3*e[j+1] + 0.4*e[j]
}

x <- x[500:1000]
x <- ts(x, start = c(1999,05), freq = 12)

Acf(x)
Pacf(x)

auto.arima(x,ic = "bic")

```

Nesse caso o `auto.arima` acertou, mas nem sempre isso ocorre. 

##VARs

Um VAR, teoricamente, é apenas uma generalização do AR. Ainda assim, do ponto de vista computacional, eles são distintos, e o VAR tem seu próprio conjunto de pacotes no R. O mais importante deles é o `vars`. 

Começamos juntando todas as séries que queremos estimar o VAR em uma matriz (use o cbind() para isso). O passo seguinte é escolher a ordem do VAR - geralmente usando algum critério de informação. O comando `VARselect` faz isso e apresenta alguns critérios de informação e a quantidade de lags que minimizam cada um.

O comando que faz a estimativa per se é o `VAR`. Ele recebe a matriz com as séries e quantos lags você quer que sejam usados - ou o critério de informação a ser usado na hora de fazer a estimativa.

Por último, queremos recuperar a resposta dinâmica de cada uma das variáveis a um choque (não só um choque na própria variável, como o efeito cruzado de um choque em outra variável). 

Vamos gerar um VAR(1) com duas variáveis apenas para ilustrar o uso do pacote:

```{r}

library(vars)

T <- 500 #número de períodos
N <- 2 #número de variáveis

u <- matrix(rnorm(T*N),nrow = N,ncol = T)

x <- matrix(0,nrow = N, ncol = T)

A <- rbind(c(0.3,-0.2),c(0.6,0.2))

for(j in 2:T){
  x[,j] <- A%*%x[,j-1] + u[,j]
}

x <- x[,400:500]
x <- t(x)
colnames(x) <- c("x","y")

VARselect(x) 
modelo <- VAR(x,p = 1)
plot(irf(modelo, impulse = "x", response = c("x","y")))
```

Eu só pedi o plot do choque da primeira variável sobre as duas variáveis por que isso é uma ilustração. Fazer `plot(irf(modelo))` em uma seção do R, ele vai plotar os choques de todas as variáveis sobre todas as variáveis. 

##Raiz unitária

O pacote **urca** nos trás testes de raiz unitária. O teste Dickey-Fuller, um dos mais populares, é chamado pelo `ur.df()`. Vamos gerar um passeio aleatório para mostrar:

```{r}
 x <- cumsum(rnorm(1000))
summary(ur.df(x))
```

Veja que o valor crítico para o teste Dick Fuller não é o valor usual da estatística t, mas sim o valor exibido na parte debaixo da tabela do sumário do teste. Nesse caso, a qualquer nível de significância, nós não rejeitamos a hipótese de raiz unitária. Vamos testar para um caso estacionário:


```{r}

u <- rnorm(2000)
y <- rep(0,2000)

for(i in 2:2000){
  y[i] <- 0.5*y[i-1] + u[i]
}

y <- y[1000:2000]

summary(ur.df(y))

```

##Desassonalizando 

Dados de séries temporais, não raramente, apresentam sazonalidade. Por exemplo, gasto de energia elétrica tende a ser maior nos meses de dezembro a fevereiro, devido ao verão. Retirar sazonalidade é importante em muitas análises. 

Um método padrão é colocar _dummies_ para as unidades de tempo (uma para cada mês se o dado for mensal, uma para cada trimestre se for trimestral etc) e usar o _resíduo_ dessa regressão somado a média da série (já que o resíduo tem média zero, por construção). Criar as _dummies_ "no braço" pode ser tedioso, mas felizmente o pacote **forecast** trás o comando `seasonaldummy()` que cria as _dummies_ automaticamente para a série. 

```{r desazonalizando, cache=TRUE}
energia <- BETSget(1406, from = "2002-01-01")
dum <- seasonaldummy(energia)
mod <- Arima(energia, xreg = dum)
des <- resid(mod) + mean(energia)
plot(energia)
lines(des, col = 2)
legend("topleft", legend = c("C/Sazonalidade", "Sem Sazonalidade"), lty = c(1,1), col = c(1,2))
```

Outra maneira comum de dessazonalizar é usando o X13, um programa do governo americano. O X13 pode ser acessado direto do R usando o pacote **seasonal**. O comando que acessa o X13 é o `seas`. O X13 são, na verdade, _dois_ programas: um que é o X13 e o outro que é o SEATS. Ambos tem a mesma função: dessazonalizar. O X13 vem com todo tipo de método automático para detectar outliers, fazer transformações nas séries e uma infinidade de outras coisas. Nesse caso, nós vamos desligar todas essa opções:

```{r}

library(seasonal)
modelo2 <- seas(energia, transform.function = "none", regression.aictest = NULL, outlier = NULL)
```

O comando `final` obtém a série dessazonalizada: 

```{r}
plot(energia)
lines(final(modelo2), col = 2)
legend("topleft", legend = c("C/Sazonalidade", "Sem Sazonalidade"), lty = c(1,1), col = c(1,2))
```

##Filtro Hodrick-Prescott

O filtro Hodrick-Prescott (HP) é utilizado em séries não estacionárias quando queremos separar a tendência do componente ciclíco. Ele é polêmico, mas ainda é amplamente usado. No R, o pacote **mFilter** implementa ele e alguns outros. Vamos aplicar na série de energia: 

```{r}
library(mFilter)
filtrado <- mFilter(energia, "HP")
plot(filtrado)
```

Eu posso acessar a tendência e o componente cíclico usando o `filtrado$trend` e `filtrado$cycle`, no exemplo acima - que seria particularmente útil se eu quisesse utilizar os dados de cíclo para alguma estimação. 